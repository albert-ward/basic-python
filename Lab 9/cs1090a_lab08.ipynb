{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# \u003cimg style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"\u003e CS1090A Introduction to Data Science "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Lab 9: Decision Trees\n",
                "\n",
                "**Harvard University**\u003cbr/\u003e\n",
                "**Fall 2024**\u003cbr/\u003e\n",
                "**Instructors**: Pavlos Protopapas and Natesh Pillai\u003cbr/\u003e\n",
                "\u003chr style='height:2px'\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#RUN THIS CELL \n",
                "import requests\n",
                "from IPython.core.display import HTML\n",
                "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
                "HTML(styles)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Table of Contents:\n",
                "- A quick review of decision trees\n",
                "- `DecisionTreeClassifier`\n",
                "- Tuning a single decision tree (`max_depth` \u0026 `criterion`)\n",
                "- Vizualizing a decision tree with `plot_tree`)\n",
                "- Pruning\n",
                "- Feature Importance"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---------\n",
                "\n",
                "#### The Idea: Decision Trees are just flowcharts and are interpretable!\n",
                "\n",
                "\u003cimg src=\"fig/flowchart.png\" alt=\"how to fix anything\" width=\"50%\"/\u003e\n",
                "\n",
                "\n",
                "It turns out that simple flow charts can be formulated as mathematical models for classification and these models have the properties we desire:\n",
                " - interpretable by humans \n",
                " - have sufficiently complex decision boundaries \n",
                " - the decision boundaries are locally linear, each component of the decision boundary is simple to describe mathematically. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "----------\n",
                "\n",
                "#### Let's review some theory.\n",
                "\n",
                "How do we build decision trees? We use a greedy approach:\n",
                " 1. Start with an empty decision tree (undivided feature space) \n",
                " 2. Choose the ‚Äòoptimal‚Äô predictor on which to split and choose the ‚Äòoptimal‚Äô threshold value for splitting by applying a **splitting criterion (1)**\n",
                " 3. Recurse on on each new node until **stopping condition (2)** is met\n",
                " \n",
                "For classification, we label each region in the model with the label of the class to which the majority of the points within the region belong. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### So we need a (1) splitting criterion and a (2) stopping condition:\n",
                "\n",
                "  #### (1) Splitting criterion \n",
                "\u003cimg src=\"fig/split1.png\" alt=\"split1\" width=\"70%\"/\u003e\n",
                "\n",
                "---\n",
                "\n",
                "\u003cimg src=\"fig/classification error.png\" alt=\"classification error\"/\u003e\n",
                "\n",
                "---\n",
                "\u003cimg src=\"fig/split2.png\" alt=\"split2\" width=\"70%\"/\u003e"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003cimg src=\"fig/tree_loss.png\" alt=\"tree_adj\"/\u003e"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### (2) Stopping condition\n",
                "\n",
                "If we don‚Äôt terminate the decision tree learning algorithm manually, the tree will continue to grow until each region defined by the model possibly contains exactly one training point (and the model attains 100% training accuracy). **Not stopping while building a deeper and deeper tree = 100% training accuracy; What will your test accuracy be? What can we do to fix this?**\n",
                "\n",
                "To prevent the **overfitting** from happening, we could \n",
                "- Stop the algorithm at a particular depth. (=**not too deep**)\n",
                "- Don't split a region if all instances in the region belong to the same class. (=**stop when subtree is pure**)\n",
                "- Don't split a region if the number of instances in the sub-region will fall below pre-defined threshold (min_samples_leaf). (=**not too specific/small subtree**)\n",
                "- Don't use too many splits in the tree (=**not too many splits / not too complex global tree**)\n",
                "- Be content with \u003c100% accuracy training set...\n",
                "\n",
                "-------------\n",
                "\n",
                "#### Done with theory, let's get started"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib\n",
                "from matplotlib import pyplot as plt\n",
                "import seaborn as sns\n",
                "import sklearn.metrics as metrics\n",
                "from sklearn.model_selection import cross_val_score\n",
                "from sklearn.metrics import accuracy_score, roc_auc_score\n",
                "from sklearn import tree\n",
                "from sklearn.model_selection import train_test_split, learning_curve\n",
                "from sklearn.metrics import confusion_matrix\n",
                "from sklearn import datasets\n",
                "\n",
                "#new model objects\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "\n",
                "\n",
                "pd.set_option('display.width', 1500)\n",
                "pd.set_option('display.max_columns', 100)\n",
                "\n",
                "np.random.seed(42)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-------------\n",
                "\n",
                "# Decision Tree Spam Classifier"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will be working with a spam email dataset. The dataset has 57 predictors with a response variable called `Spam` that indicates whether an email is spam or not spam. The goal is to be able to create a classifier or method that acts as a spam filter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "spam_df = pd.read_csv('data/spam.csv')\n",
                "display(spam_df.head())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The predictors are all quantitative. They represent certain features  of an email like the frequency of the word 'discount.' The we will use the binary `spam` variable in the final column as our response for classification."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Link to description : https://archive.ics.uci.edu/ml/datasets/spambase"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Split data into train and test"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Split spam_df into train and test data with a random seed of 109\n",
                "data_train, data_test = train_test_split(spam_df, random_state=0, test_size=.2, stratify=spam_df.spam)\n",
                "\n",
                "# Split predictor and response columns\n",
                "X_train, y_train = data_train.drop(['spam'], axis=1), data_train['spam']\n",
                "X_test , y_test  = data_test.drop(['spam'] , axis=1), data_test['spam']\n",
                "\n",
                "print(\"Shape of Training Set :\", data_train.shape)\n",
                "print(\"Shape of Testing Set :\" , data_test.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_train.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can check that the proportion of spam cases is roughly evenly represented in both the training and test set.\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Check Percentage of Spam in Train and Test Set\n",
                "pct_spam_tr = 100*y_train.mean()\n",
                "pct_spam_te = 100*y_test.mean()\n",
                "                                                  \n",
                "print(f\"Percentage of Spam in Training Set \\t : {pct_spam_tr:0.2f}%\")\n",
                "print(f\"Percentage of Spam in Testing Set \\t : {pct_spam_te:0.2f}%\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "-----------\n",
                "\n",
                "# Fitting an Optimal Single Decision Tree (by Depth) :"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here, for each candidate `max_depth` and `criterion` combination, we fit a single tree to our spam training data using 5-fold cross validation.\n",
                "\n",
                "We store the CV accuracy scores in a DataFrame along with the hyperparmeter settings that generated them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Find optimal depth of trees\n",
                "\n",
                "df = pd.DataFrame(columns=['criterion', 'depth', 'all_cv', 'mean_cv'])\n",
                "\n",
                "criterion = ['gini', 'entropy']\n",
                "\n",
                "first_depth = 2\n",
                "final_depth = 30\n",
                "step = 2\n",
                "\n",
                "results = []\n",
                "for cur_criterion in criterion:      \n",
                "    for max_depth in range(first_depth, final_depth+1, step):\n",
                "        dt = DecisionTreeClassifier(criterion=cur_criterion , max_depth=max_depth)\n",
                "        scores = cross_val_score(estimator=dt, X=X_train, y=y_train, cv=5, n_jobs=-1)\n",
                "        \n",
                "        cur_results = {'criterion': cur_criterion,\n",
                "                      'depth': max_depth,\n",
                "                      'all_cv': scores,\n",
                "                      'mean_cv': scores.mean()}\n",
                "        results.append(cur_results)\n",
                "df = pd.DataFrame(results)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": [
                "display(df)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Some dataframe manipulations for our x,y construction for the plot below:"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We can then visualize the validation accuracy for the different hyperparameters."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(7, 4))\n",
                "\n",
                "plt.plot(df[df.criterion == 'gini'].depth,\n",
                "         df[df.criterion == 'gini'].mean_cv, 'b-', marker='o', alpha = 0.6, label='Gini')\n",
                "plt.plot(df[df.criterion == 'entropy'].depth,\n",
                "         df[df.criterion == 'entropy'].mean_cv, 'r-', marker='o', alpha = 0.6, label='Entropy')\n",
                "plt.ylabel(\"Cross Validation Accuracy\")\n",
                "plt.xlabel(\"Maximum Depth\")\n",
                "plt.title('Variation of Accuracy with Depth - Simple Decision Tree')\n",
                "plt.legend()\n",
                "plt.grid(alpha = 0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Let's visualize a plot with the Confidence Bands!"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Also, if we wanted to get **the Confidence Bands of these results**, how would we? It's as simple as a combination of getting variance using ```scores.std()``` and ```plt.fill_between()```."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_gini = df[df['criterion'] == 'gini']\n",
                "df_entropy = df[df['criterion'] == 'entropy']\n",
                "\n",
                "x_gini = df_gini['depth'].values.astype(float)\n",
                "y_gini = df_gini['mean_cv'].values.astype(float)\n",
                "\n",
                "x_entropy = df_entropy['depth'].values.astype(float)\n",
                "y_entropy = df_entropy['mean_cv'].values.astype(float)\n",
                "\n",
                "stds_gini = np.array([ np.std(scores) for scores in df_gini['all_cv']], dtype = float) \n",
                "stds_entropy = np.array([ np.std(scores) for scores in df_entropy['all_cv']], dtype = float)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axes = plt.subplots(2, 1, figsize=(8, 5))\n",
                "\n",
                "#Plot\n",
                "axes[0].fill_between(df.loc[df.criterion == 'gini'].depth, y_gini + stds_gini, \n",
                "                     y_gini - stds_gini, alpha=0.2)\n",
                "axes[0].plot(x_gini, y_gini, 'b-', marker='o')\n",
                "axes[0].set_ylabel(\"Cross Validation Accuracy\")\n",
                "axes[0].set_title('Variation of Accuracy with Depth - Single Decision Tree')\n",
                "axes[0].legend(['std','Gini'])\n",
                "axes[0].grid(alpha = 0.3)\n",
                "\n",
                "axes[1].fill_between(x_entropy, y_entropy + stds_entropy, \n",
                "                     y_entropy - stds_entropy, \n",
                "                     color = 'r', alpha=0.2)\n",
                "axes[1].plot(x_entropy, y_entropy, 'r-', marker='o')\n",
                "axes[1].set_ylabel(\"Cross Validation Accuracy\")\n",
                "axes[1].set_xlabel(\"Maximum Depth\")\n",
                "axes[1].legend(['std','Entropy'])\n",
                "axes[1].grid(alpha = 0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Let's visualize a boxplot! (**Gini impurity** only)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If we want to display it as a boxplot we first construct a dataframe with all the scores and second we use ```sns.boxplot(...)```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "display(df_gini.head())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "ds = range(first_depth, final_depth + 1, step)\n",
                "\n",
                "plt.figure(figsize=(7,4))\n",
                "plt.boxplot([df_gini.loc[df_gini.depth==d, 'all_cv'].values[0] for d in ds])\n",
                "plt.scatter(range(1,len(ds)+1), df_gini.mean_cv, color='red', alpha=0.3, label='Mean CV Acc')\n",
                "plt.xticks(range(1,len(ds)+1), labels=ds)\n",
                "plt.ylabel(\"cross-validation accuracy\")\n",
                "plt.xlabel(\"max depth\")\n",
                "plt.title(\"Spam Classifier Trees (Gini)\")\n",
                "plt.grid(alpha = 0.3)\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Question:** Which depth are you going to pick?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Let's extract the best_depth value from these two dataframes, *df_gini* and *df_entropy*.\n",
                "\n",
                "We need to create the new variable *best_depth* for each dataframe. \n",
                "\n",
                "How to get the index of the maximum value from the given array?\n",
                "\n",
                "```hint: np.argmax(target array)```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# What does this do?\n",
                "\n",
                "mean_CV_acc_gini = df_gini['mean_cv']\n",
                "mean_CV_acc_entropy = df_entropy['mean_cv']\n",
                "\n",
                "best_idx_gini = np.argmax(mean_CV_acc_gini)\n",
                "best_idx_entropy = np.argmax(mean_CV_acc_entropy)\n",
                "\n",
                "best_depth_gini = df_gini['depth'].iloc[best_idx_gini]\n",
                "best_depth_entropy = df_entropy['depth'].iloc[best_idx_entropy]\n",
                "\n",
                "print('The best depth based on Gini impurity was found to be: ', best_depth_gini)\n",
                "print('The best depth based on Entropy was found to be: ', best_depth_entropy)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Evalaute the performance at the best depth\n",
                "model_tree_gini = DecisionTreeClassifier(max_depth=best_depth_gini, criterion = 'gini')\n",
                "model_tree_entropy = DecisionTreeClassifier(max_depth=best_depth_entropy, criterion ='entropy')\n",
                "\n",
                "model_tree_gini.fit(X_train, y_train)\n",
                "model_tree_entropy.fit(X_train, y_train)\n",
                "\n",
                "#Check Accuracy of Spam Detection in Train and Test Set (Gini Impurity)\n",
                "acc_trees_train_gini = accuracy_score(y_train, model_tree_gini.predict(X_train))\n",
                "acc_trees_test_gini  = accuracy_score(y_test,  model_tree_gini.predict(X_test))\n",
                "\n",
                "print(\"================ [Gini Impurity] ================\")\n",
                "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_train_gini))\n",
                "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_test_gini))\n",
                "\n",
                "#Check Accuracy of Spam Detection in Train and Test Set (Entropy)\n",
                "acc_trees_train_entropy = accuracy_score(y_train, model_tree_entropy.predict(X_train))\n",
                "acc_trees_test_entropy = accuracy_score(y_test,  model_tree_entropy.predict(X_test))\n",
                "\n",
                "print(\"\\n================ [Entropy] ================\")\n",
                "print(\"Simple Decision Trees: Accuracy, Training Set \\t : {:.2%}\".format(acc_trees_train_entropy))\n",
                "print(\"Simple Decision Trees: Accuracy, Testing Set \\t : {:.2%}\".format(acc_trees_test_entropy))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Let's visualize a confusion matrix with ```plot_confusion_matrix```"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### How to visualize the classification result using a Confusion matrix? ####\n",
                "\n",
                "\u003cimg src=\"fig/confusion_matrix.png\" alt=\"classification error\" width=\"300\"/\u003e\n",
                "\n",
                "\u003cimg src=\"fig/confusion_matrix2.png\" alt=\"classification error\" width=\"400\"/\u003e\n",
                "\n",
                "*source: wikipedia*\n",
                "\n",
                "We can use the sklearn library function, **plot_confusion_matrix**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import ConfusionMatrixDisplay\n",
                "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(14,8))\n",
                "ConfusionMatrixDisplay.from_estimator(model_tree_gini, X_test, y_test, cmap=plt.cm.Blues, ax = axes[0]);\n",
                "ConfusionMatrixDisplay.from_estimator(model_tree_entropy, X_test, y_test, cmap=plt.cm.Blues, ax = axes[1])\n",
                "axes[0].set_title('Simple Decision Tree - Gini')\n",
                "axes[1].set_title('Simple Decision Tree - Entropy')\n",
                "# plt.rc('font', size=18)\n",
                "plt.tight_layout()\n",
                "\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### How to visualize a Decision Tree with ```sklearn.tree.plot_tree```\n",
                "\n",
                "*Question:* Do you think this tree is interpretable? What do you think about a the maximal depth of the tree?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003c!-- - Let's look at the resulting text ```decision_tree.dot``` --\u003e"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\u003c!-- - Let's convert our (hard to read) written decision tree (```decision_tree.dot```) into an intuitive image file format: ```image_tree.png```\n",
                "- \u003cspan style=\"color:red\"\u003e**NOTE:**\u003c/span\u003e You might need to install the ```pydot``` package by typing the following command in your terminal: ```pip install pydot``` or you can install from within the jupyter notebook by running the following cell: ```! pip install pydot``` --\u003e"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 8))\n",
                "gini_tree = tree.plot_tree(model_tree_gini, max_depth = 1);"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(15, 8))\n",
                "entropy_tree = tree.plot_tree(model_tree_entropy, max_depth = 5);"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Pruning\n",
                "\n",
                "Limiting how far a tree can grow using hyperparameters like `max_depth` or `max_leaf_nodes` can help prevent overfitting, but they can lead to trees with high bias that can underfit the training data.\n",
                "\n",
                "Another way to address overfitting is to train a deep tree and then prune it back. This is done using the `ccp_alpha` hyperparameter. This is the cost complexity parameter. The cost complexity is the size of the tree. This is analogous to the regularization (hyper)parameter we saw with Ridge and Lasso. A higher value of thehyperparameter means more regularization and a less complex model which is less likely to over fit.\n",
                "\n",
                "We saw that the optimal entropy tree above was rather deep. But we can prune it back."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "ccp_alpha = 0.05\n",
                "entropy_pruned = DecisionTreeClassifier(max_depth=best_depth_entropy, criterion ='entropy', ccp_alpha=ccp_alpha)\n",
                "entropy_pruned.fit(X_train, y_train)\n",
                "entropy_pruned.score(X_test, y_test)\n",
                "tree.plot_tree(entropy_pruned);"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Minimal cost complexity pruning recursively finds the node with the ‚Äúweakest link‚Äù. The weakest link is characterized by an effective alpha, where the nodes with the smallest effective alpha are pruned first. To get an idea of what values of ccp_alpha could be appropriate, scikit-learn provides [DecisionTreeClassifier.cost_complexity_pruning_path](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.cost_complexity_pruning_path) that returns the effective alphas and the corresponding total leaf impurities at each step of the pruning process. As alpha increases, more of the tree is pruned, which increases the total impurity of its leaves."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "path = model_tree_entropy.cost_complexity_pruning_path(X_train, y_train)\n",
                "ccp_alphas, impurities = path.ccp_alphas, path.impurities"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the following plot, the maximum effective alpha value is removed, because it is the trivial tree with only one node."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, ax = plt.subplots()\n",
                "ax.plot(ccp_alphas[:-1], impurities[:-1], marker=\"o\", drawstyle=\"steps-post\")\n",
                "ax.set_xlabel(\"effective alpha\")\n",
                "ax.set_ylabel(\"total impurity of leaves\")\n",
                "ax.set_title(\"Total Impurity vs effective alpha for training set\");"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we train a decision tree using the effective alphas. The last value in ccp_alphas is the alpha value that prunes the whole tree, leaving the tree, clfs[-1], with one node."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "clfs = []\n",
                "for ccp_alpha in ccp_alphas:\n",
                "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
                "    clf.fit(X_train, y_train)\n",
                "    clfs.append(clf)\n",
                "print(\n",
                "    \"Number of nodes in the last tree is: {} with ccp_alpha: {}\".format(\n",
                "        clfs[-1].tree_.node_count, ccp_alphas[-1]\n",
                "    )\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For the remainder of this example, we remove the last element in clfs and ccp_alphas, because it is the trivial tree with only one node. Here we show that the number of nodes and tree depth decreases as alpha increases."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "clfs = clfs[:-1]\n",
                "ccp_alphas = ccp_alphas[:-1]\n",
                "\n",
                "node_counts = [clf.tree_.node_count for clf in clfs]\n",
                "depth = [clf.tree_.max_depth for clf in clfs]\n",
                "fig, ax = plt.subplots(2, 1)\n",
                "ax[0].plot(ccp_alphas, node_counts, marker=\"o\", drawstyle=\"steps-post\")\n",
                "ax[0].set_xlabel(\"alpha\")\n",
                "ax[0].set_ylabel(\"number of nodes\")\n",
                "ax[0].set_title(\"Number of nodes vs alpha\")\n",
                "ax[1].plot(ccp_alphas, depth, marker=\"o\", drawstyle=\"steps-post\")\n",
                "ax[1].set_xlabel(\"alpha\")\n",
                "ax[1].set_ylabel(\"depth of tree\")\n",
                "ax[1].set_title(\"Depth vs alpha\")\n",
                "fig.tight_layout()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "When ccp_alpha is set to zero and keeping the other default parameters of DecisionTreeClassifier, the tree overfits, leading to a 100% training accuracy and 88% testing accuracy. As alpha increases, more of the tree is pruned, thus creating a decision tree that generalizes better. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_scores = [clf.score(X_train, y_train) for clf in clfs]\n",
                "test_scores = [clf.score(X_test, y_test) for clf in clfs]\n",
                "\n",
                "fig, ax = plt.subplots(figsize=(20,8))\n",
                "ax.set_xlabel(\"alpha\")\n",
                "ax.set_ylabel(\"accuracy\")\n",
                "ax.set_title(\"Accuracy vs alpha for training and testing sets\")\n",
                "ax.plot(ccp_alphas, train_scores, marker=\"o\", label=\"train\", drawstyle=\"steps-post\")\n",
                "ax.plot(ccp_alphas, test_scores, marker=\"o\", label=\"test\", drawstyle=\"steps-post\")\n",
                "ax.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f\"ccp_alpha that maximizes test score: {ccp_alphas[np.argmax(test_scores)]:.5f}\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ü§î **Should we choose which model to deploy based on the test performance?**"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Preprocessing for Decision Trees\n",
                "\n",
                "Unlike many other models, decision trees have some nice properties when it comes to preprocessing:\n",
                "\n",
                "1. **Scaling**: Trees don't require feature scaling because they use thresholds rather than distances\n",
                "   - No need for StandardScaler or MinMaxScaler\n",
                "   - Trees make splits based on relative ordering, not absolute values\n",
                "\n",
                "2. **Categorical Variables**: \n",
                "   - For binary categories, any encoding works equally well\n",
                "   - For multi-class categories:\n",
                "     - One-hot encoding is preferred\n",
                "     - No need to drop_first (unlike linear models) since trees can handle the redundancy\n",
                "```python\n",
                "# Example of proper categorical encoding for trees\n",
                "X_encoded = pd.get_dummies(X, columns=['categorical_column'])\n",
                "# No need for: drop_first=True\n",
                "```\n",
                "\n",
                "3. **Missing Values**: \n",
                "   - Trees can handle missing values naturally (though sklearn's implementation doesn't)\n",
                "   - Consider using SimpleImputer with strategy='most_frequent' for categorical\n",
                "   - Use strategy='median' for numerical features"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Handling Class Imbalances\n",
                "\n",
                "Class imbalance occurs when some classes have many more samples than others. This is common in real-world scenarios like spam detection or fraud detection. With imbalanced datasets, accuracy can be misleading - a model could achieve high accuracy by simply predicting the majority class!\n",
                "\n",
                "There are several approaches to handle class imbalances:\n",
                "\n",
                "1. **Class Weights**: Tell the model to pay more attention to minority classes\n",
                "   \n",
                "```python\n",
                "# Add weights inversely proportional to class frequencies\n",
                "from sklearn.utils.class_weight import compute_class_weight\n",
                "\n",
                "class_weights = compute_class_weight('balanced', \n",
                "                                     classes=np.unique(y_train),\n",
                "                                     y=y_train)\n",
                "                                   \n",
                "dt = DecisionTreeClassifier(class_weight='balanced')  # Or pass dict of weights\n",
                "```\n",
                "\n",
                "2. **Upsampling**: Replicate minority class samples\n",
                "```python\n",
                "from imblearn.over_sampling import RandomOverSampler\n",
                "\n",
                "ros = RandomOverSampler(random_state=42)\n",
                "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
                "print('Original dataset shape:', Counter(y_train))\n",
                "print('Resampled dataset shape:', Counter(y_train_ros))\n",
                "```\n",
                "\n",
                "3. **SMOTE**: Create synthetic minority samples (requires a pip install)\n",
                "```python\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
                "print('Original dataset shape:', Counter(y_train))\n",
                "print('Resampled dataset shape:', Counter(y_train_sm))\n",
                "```"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Alternative Metrics to Accuracy (revisted)\n",
                "\n",
                "When dealing with imbalanced classes, accuracy can be misleading. Consider these alternatives:\n",
                "\n",
                "1. **Precision**: Of the positive predictions, how many were correct?\n",
                "   - Important when false positives are costly\n",
                "   - Example: Spam detection (don't want to block legitimate emails)\n",
                "\n",
                "2. **Recall**: Of the actual positive cases, how many did we catch?\n",
                "   - Important when false negatives are costly\n",
                "   - Example: Disease detection (don't want to miss sick patients)\n",
                "\n",
                "3. **F1 Score**: Harmonic mean of precision and recall\n",
                "   - Balances precision and recall\n",
                "\n",
                "```python\n",
                "from sklearn.metrics import classification_report\n",
                "\n",
                "# Get comprehensive metrics\n",
                "print(classification_report(y_test, y_pred))\n",
                "\n",
                "# For binary classification, you can of course also plot the ROC curve\n",
                "from sklearn.metrics import RocCurveDisplay\n",
                "RocCurveDisplay.from_estimator(model, X_test, y_test)\n",
                "plt.show()\n",
                "```"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "--------\n",
                "\u003cdiv class=\"alert alert-success\"\u003e\n",
                "    \u003cstrong\u003eüèãüèª‚Äç‚ôÇÔ∏è TEAM ACTIVITY:\u003c/strong\u003e Tuning a Spam Detection Decision Tree \u003c/div\u003e  \n",
                "\n",
                "**Tune some of the available decision tree hyperparameters and select the best model. Finally, evaluate your selected model on the test data.**\n",
                "\n",
                "- You must be able to justify your choice for the best model **without** reference to test performance (i.e., no tuning to the test data!)\n",
                "- Consult the [DecisionTreeClassifier documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) to see the full list of available hyperparameters. You certainly do not need to tune all of them here!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# your code here\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Pros of Decision Trees:**\n",
                "- Very straigtforward models, easy to explain to people, even easier than linear regression.\n",
                "- Transparent models, easy to interpret\n",
                "- Not as sensitive to multicollinearity as some other models\n",
                "- Do not require scaling of data, not sensitive to variables having high difference in range\n",
                "- Can handle both numerical and caterorical predictors (in some languages like R you don't even have to encode categorical data as zeros and ones, R handles it out-of-the-box)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Cons of Decision Trees:**\n",
                "- Not very competitive in terms of predictive accuracy, other classification and regression approaches outperform trees.\n",
                "- Overfit very quickly.\n",
                "- Very non-robust, a small change in the data can cause a large change in the final estimated tree, In other words they suffer from high variance."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "What can we do to make it better?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's say we have a set of $n$ independent observations $Z_1, Z_2, Z_3, ..., Z_n$. Each $Z_i$ has a variance of $\\sigma^2$. What would be the variance of the mean of the observations $\\bar{Z}$ ?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "It would be $\\frac{\\sigma^2}{n}$, which is lower than each independent observation would have."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Feature Importance"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Decision Tree objects have a `feature_importances_` attribute. This is a record of how much each feature's splits contributed to the reduction in the model's splitting criterion.\n",
                "\n",
                "The idea is that features whose splits reduced the criterion the most are the most important. But there are reasons to be skeptical about this approach to feature importance..."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Feature Importance Analysis: 3 Approaches\n",
                "\n",
                "Decision trees offer multiple ways to assess feature importance:\n",
                "\n",
                "1. **Built-in Feature Importance**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Built-in feature importance\n",
                "importances = model_tree_entropy.feature_importances_\n",
                "feature_imp = pd.DataFrame({\n",
                "    'feature': X_train.columns,\n",
                "    'importance': importances\n",
                "}).sort_values('importance', ascending=False)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.barh(feature_imp.head(10)['feature'], \n",
                "         feature_imp.head(10)['importance'])\n",
                "plt.title('Top 10 Feature Importances (Built-in)')\n",
                "plt.xlabel('Importance')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "2. **Permutation Importance**: More robust than built-in importance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.inspection import permutation_importance\n",
                "\n",
                "# Permutation Importance (more robust)\n",
                "result = permutation_importance(\n",
                "    model_tree_entropy, X_test, y_test,\n",
                "    n_repeats=10,\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "# Create dataframe of permutation importances\n",
                "perm_imp = pd.DataFrame({\n",
                "    'feature': X_test.columns,\n",
                "    'importance_mean': result.importances_mean,\n",
                "    'importance_std': result.importances_std\n",
                "}).sort_values('importance_mean', ascending=False)\n",
                "\n",
                "# Plot top 10 features with error bars\n",
                "plt.figure(figsize=(10, 6))\n",
                "top_10 = perm_imp.head(10)\n",
                "plt.barh(range(len(top_10)), top_10['importance_mean'],\n",
                "         xerr=top_10['importance_std'], capsize=5)\n",
                "plt.yticks(range(len(top_10)), top_10['feature'])\n",
                "plt.title('Top 10 Feature Importances (Permutation)')\n",
                "plt.xlabel('Importance')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "3. **Bootstrap Analysis**: Assess stability of importance measures"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Bootstrap Analysis of Feature Importance\n",
                "n_iterations = 100\n",
                "n_features = X_train.shape[1]\n",
                "bootstrap_importances = np.zeros((n_iterations, n_features))\n",
                "\n",
                "for i in range(n_iterations):\n",
                "    # Bootstrap sample\n",
                "    indices = np.random.randint(0, len(X_train), len(X_train))\n",
                "    X_boot = X_train.iloc[indices]\n",
                "    y_boot = y_train.iloc[indices]\n",
                "    \n",
                "    # Fit model and get importance\n",
                "    dt = DecisionTreeClassifier(random_state=42)\n",
                "    dt.fit(X_boot, y_boot)\n",
                "    bootstrap_importances[i,:] = dt.feature_importances_\n",
                "\n",
                "# Calculate confidence intervals\n",
                "importance_stats = pd.DataFrame({\n",
                "    'feature': X_train.columns,\n",
                "    'mean_importance': bootstrap_importances.mean(axis=0),\n",
                "    'std_importance': bootstrap_importances.std(axis=0)\n",
                "}).sort_values('mean_importance', ascending=False)\n",
                "\n",
                "# Top 10 features with confidence intervals\n",
                "plt.figure(figsize=(10, 6))\n",
                "top_10 = importance_stats.head(10)\n",
                "plt.barh(range(len(top_10)), top_10['mean_importance'],\n",
                "         xerr=top_10['std_importance'], capsize=5)\n",
                "plt.yticks(range(len(top_10)), top_10['feature'])\n",
                "plt.title('Top 10 Feature Importances (Bootstrap Analysis)')\n",
                "plt.xlabel('Mean Importance')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Finally, a comparison across all methods."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Top 5 most important features across all methods\n",
                "print(\"\\nTop 5 Most Important Features Summary:\")\n",
                "print(\"\\nBuilt-in Importance:\")\n",
                "print(feature_imp[['feature', 'importance']].head())\n",
                "print(\"\\nPermutation Importance:\")\n",
                "print(perm_imp[['feature', 'importance_mean', 'importance_std']].head())\n",
                "print(\"\\nBootstrap Importance:\")\n",
                "print(importance_stats[['feature', 'mean_importance', 'std_importance']].head())"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "üåà **The End**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
