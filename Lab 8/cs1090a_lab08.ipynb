{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### \u003cimg style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://github.com/Harvard-IACS/2018-CS109A/blob/master/content/styles/iacs.png?raw=true\"\u003e CS1090A Introduction to Data Science \n",
                "\n",
                "## Lab 8: Causal Inference in Practice\n",
                "**Harvard University**\u003cbr\u003e\n",
                "**Fall 2024**\u003cbr\u003e\n",
                "**Instructors:** Pavlos Protopapas, Natesh Pillai, Chris Gumb\u003cbr\u003e\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import sklearn as sk\n",
                "from sklearn.linear_model import LinearRegression, LogisticRegression, LogisticRegressionCV\n",
                "\n",
                "from scipy import stats\n",
                "import statsmodels.api as sm\n",
                "\n",
                "from matplotlib import pyplot as plt, patches\n",
                "import seaborn as sns\n",
                "from IPython.display import display"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Table of Contents\n",
                "\n",
                "- Yelp A/B Test Data \n",
                "- EDA\n",
                "- Randomization Tests\n",
                "\n",
                "- UMASS Payroll Data\n",
                "- Propensity Score Estimation\n",
                "- Causal Effect Estimation\n",
                "   "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Yelp A/B Test Data\n",
                "\n",
                "Our first data set will be based on an experiment that Yelp ran.  Yelp's business model is based on collecting revenue through advertising: they get paid everytime a user clicks on this advertisement (and the amount of money is not always the same).  \n",
                "\n",
                "They were interested in determining if there was a better way to present advertising to their users, and so they designed an A/B test.  When a user is searching through their map feature, *sponsored results*  (i.e., advertisements) are presented to them in one of two ways in this experiment (randomly assigned, and users were *blinded*): \n",
                "  \n",
                "+ **Treatment A** (the standard, `control` version) presented sponsored results that do **not** respect map search geographical constraints (depicted to the left below).\n",
                "+ **Treatment B** (the new `treatment` version) presented sponsored results that do respect map search geographical constraints (depicted to the right below).\n",
                "\n",
                "Our goal is to determine whether the new way of presenting ads (honoring geographical constraints) improves their advertising revenue.\n",
                "\n",
                "$^*$Note: this just one way a user can interact with Yelp.  Most users do not use the map feature.\n",
                "\n",
                "\n",
                "\u003cimg src='fig/yelp_abtest.png' width='1000px'\u003e"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data set contains several variables:\n",
                "\n",
                "+ `treatment`: A categorical variable indicating whether the observation was in the treatment or control group (`treatment`/`control`).  \n",
                "+ `desktop`: A categorical variable indicating whether the user accessed the desktop or mobile platform (`desktop`/`mobile`). \n",
                "+ `desktop_binary`: A binary variable indicating whether the user accessed the desktop platform. \n",
                "+ `local_service`: A categorical variable taking a value `local` if the search was for a local service like plumbing, moving, or construction OR `non-local` if the search was for anything else, like a restaurant, bar, or shop; or  (`non-local`/`local`).\n",
                "+ `local_binary`: A binary variable indicating whether the search was for a local service \n",
                "+ `eligible`: A categorical variable indicating whether the search was eligible to be shown an advertisement (`eligible`/`not eligible`). For example, Yelp doesn't show advertisements on some sensative searches, such as \"hospital.\"\n",
                "+ `eligible_binary`: A binary variable indicating whether the search was eligible to be shown an advertisement.\n",
                "+  `ad_shown`: A categorical variable indicating whether an advertisement was shown (`shown`/`not shown`).\n",
                "+  `ad_shown_binary`: A binary variable indicating whether an advertisement was shown. \n",
                "+  `ad_click`: A categorical variable indicating whether a shown advertisement was clicked (`clicked`/`not clicked`). Note that this variable is `not clicked` whenever an advertisement is `not shown`.\n",
                "+  `ad_click_binary`: A binary variable indicating whether a shown advertisement was clicked. \n",
                "+  `revenue`: The revenue collected from the search. Yelp only receives a payment if the advertisement is clicked.\n",
                "+  `date`: The date when the user accessed Yelp.\n",
                "+  `weekend`: A binary indicator whether the date fell over the weekend (Saturday or Sunday).\n",
                "+  `day_number`: The day of the study (day of the month within January).\n",
                "\n",
                "We read in the data below."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "yelp = pd.read_csv('data/yelp_df.csv')\n",
                "yelp.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## **Exploratory Data Analysis**\n",
                "\n",
                "\n",
                "#### Step 1: Visuals and Summaries\n",
                "\n",
                "We may want to explore some of the following:\n",
                "*   The proportion of local vs. non-local searches and desktop vs. mobile searches.\n",
                "*   The proportion of eligible vs. not eligible searches, ads shown vs. no ads shown, and clicked vs. not clicked.\n",
                "*   Revenue (compute the sum and mean), then plot a histogram. What is the interpretation of the mean revenue?\n",
                "*   Does revenue differ across local/non-local searches? What about mobile/desktop? Why did some searches not generate any revenue? What if you filter out rows that generate 0 revenue?\n",
                "*   ...or other relationship you may be interested in.\n",
                "\n",
                "**Hint:** Try using a boxplot to visualize how revenue differs across the two types of searches (treatments), and a barplot to visualize how *click-through rate* differs across the two types of searches (treatments).\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Example: basic counts, and a sanity check via a hypothesis test\n",
                "print(yelp['treatment'].value_counts())\n",
                "\n",
                "display(pd.crosstab(yelp['treatment'],yelp['desktop']))\n",
                "\n",
                "# Check for independence of treatment and desktop in determining crosstab values\n",
                "chi2test = stats.chi2_contingency(pd.crosstab(yelp['treatment'],yelp['desktop']))\n",
                "print(\"Chi-sq stat =\",chi2test[0],\"pvalue =\",chi2test[1])\n",
                "\n",
                "\n",
                "#chi2test = (\"statistic\", \"pvalue\", \"dof\", \"expected_freq\") "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "###############\n",
                "# Your code here:\n",
                "# We get you started\n",
                "###############\n",
                "\n",
                "fig, axs = plt.subplots(2, 3, figsize=(18, 10))\n",
                "axs = axs.flatten()\n",
                "\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 1.2: **Conduct hypothesis tests**\n",
                "\n",
                "We want to compare the proportion of eligible ads in the control group to the proportion in the treatment group. Generally, when comparing proportions, we use a proportions test with the `stats.chi2_contingency()` function. However, because of the large sample size, the t-test gives approximately the same results as a proportions test. Therefore, you can compare `Eligible` across the two groups using either the `stats.ttest_ind` function or `stats.chi2_contingency`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "################\n",
                "# your code here\n",
                "################"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 1.3: **Interpret results**\n",
                "\n",
                "What can you conclude based on the EDA and hypothesis test?  What do these results mean to the company?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here* "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Assessing Treatment Effect\n",
                "\n",
                "Below we provide you the code to run a randomization test (and the related two-sample t-test) to determine whether the click-through rate is different in the two treatments.  Your task is to \n",
                "+ (1) interpret the results and \n",
                "+ (2) perform a randomization test for revenue."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Testing to see if click-through rate is different in the 2 groups\n",
                "\n",
                "y = yelp['ad_click_binary']\n",
                "x = pd.Series(1*(yelp['treatment']=='treatment'))\n",
                "\n",
                "obs_diff = np.mean(y[x==1]) - np.mean(y[x==0])\n",
                "print(\"The estimated diff in click-through rate is:\", obs_diff)\n",
                "\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# randomization/permutation test for click-through-rate\n",
                "np.random.seed(109)\n",
                "nsims = 1000\n",
                "perm_diffs = []\n",
                "\n",
                "for i in np.arange(nsims):\n",
                "    x_perm = np.random.permutation(x)\n",
                "    perm_diffs.append(np.mean(y[x_perm==1]) - np.mean(y[x_perm==0]))\n",
                "\n",
                "p_value = np.mean(np.abs(perm_diffs) \u003e= np.abs(obs_diff))\n",
                "p_value"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.hist(perm_diffs, label=\"simulations under null\")\n",
                "plt.axvline(obs_diff,c=\"orange\", label=\"abs(observed)\")\n",
                "plt.axvline(-obs_diff,c=\"orange\");\n",
                "plt.xlabel(\"difference in click-through rate\")\n",
                "plt.legend();"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 2.1: Interpret the results\n",
                "\n",
                "Which group has a higher click-through rate?  Is this difference statistically significant?  What is the p-value for the randomization test?  Why is it so small?  What does this mean for the company?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*your answer here*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 2.2: Perform a Randomization Test\n",
                "\n",
                "Perform a randomization test to see if revenue if different in the 2 treatment groups.\n",
                "\n",
                "Which group has a higher click-through rate?  Is this difference statistically significant?  What is the p-value for the randomization test?  Why is it so small?\n",
                "\n",
                "*Hint:* `np.random.permutation()` can be useful here. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "################\n",
                "# your code here\n",
                "# Test to see if revenue is different in the 2 groups\n",
                "################\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 2.3: Interpret the results\n",
                "\n",
                "Which group had a higher mean revenue?  Is this difference statistically significant?  What is the p-value for the randomization test?  What does this mean for the company?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your answer here*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## UMASS Payroll Data\n",
                "\n",
                "Data were collected from the publicly available payroll data for employees of UMASS.  The variables in the data set `UMASS_payroll_2018.csv` include:\n",
                "\n",
                "+ `year`: 2018 for everyone\n",
                "+ `sex`: whether the employee self-identifies as `male` or `female`\n",
                "+ `position_title`: the employee's position at the University\n",
                "+ `position_type`: `Full Time Employee` for everyone (`Part Time Employee`s were filtered out).  \n",
                "+ `service_end_date`: the date of last employment in the year (Dec 22 is when the fiscal year ended).  This could be used to filter out those that left before the year ended\n",
                "+ `days_employed`: how many days of 2018 was the pay based off of\n",
                "+ `pay_total`: total amount of pay received, in US dollars\n",
                "+ `annual_rate`: the contracted salary signed, in US dollars\n",
                "+ `location`: the campus of the employees' primary appointment\n",
                "+ `contract`: which type of employee is it based on contract type/group \n",
                "+ `bargaining_group_num`: a key/id for the contract type/group\n",
                "+ `bargaining_group_title`: the title of the contract type/group\n",
                "\n",
                "Use this dataset to assess the *causal effect* of `sex` on `pay`.  Note: we can not randomize `sex`, but we can still estimate a quasi-causal effect as to whether `sex` is a determinant of differences in `pay_total`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "umass = pd.read_csv('data/UMASS_Payroll_2018.csv')\n",
                "\n",
                "umass['log2pay'] = np.log2(umass['pay_total'])\n",
                "umass['female'] = 1*(umass['sex'] == 'female')\n",
                "\n",
                "umass.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 3.1: EDA\n",
                "\n",
                "Explore the following (visually and numerically):\n",
                "*   The difference in pay for males and females.\n",
                "*   Any differences in pay across locations\n",
                "*   Any differences in the distribution of sexes across 'location'\n",
                "*   Any differences in pay across 'bargaining_group_title'\n",
                "*   Any differences in the distribution of sexes across 'bargaining_group_title'\n",
                "\n",
                "$^*$Note: you may want to consider using `log2pay` instead of `paytotal` throught this problem.  Why?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Here are univariate summaries to get you started\n",
                "\n",
                "print(umass['sex'].value_counts())\n",
                "print(umass['position_title'].nunique())\n",
                "print(umass['location'].value_counts())\n",
                "print(umass['bargaining_group_title'].value_counts())\n",
                "\n",
                "\n",
                "umass[['pay_total','days_employed','log2pay']].describe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "################\n",
                "# your code here\n",
                "################"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 3.2: Estimate Propensity Scores of `sex`\n",
                "\n",
                "Below we provide the code to estimate the "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "################\n",
                "# fit a logistic regression model to estimate the \n",
                "# probability of being female based on the predictors\n",
                "# `location`,`bargaining_group_title`, and `days_employed`\n",
                "# save these probabilities as `propensity_scores`\n",
                "################\n",
                "\n",
                "# create dummies, don't forget to set 'drop_first=True'.\n",
                "# drop any dummies that have fewer than 20 observations in them\n",
                "dummies = pd.get_dummies(umass[['location','bargaining_group_title']] ,drop_first=True)\n",
                "\n",
                "# create X\n",
                "X = pd.concat([umass[['days_employed']],dummies],\n",
                "              axis=1)\n",
                "X = X[X.columns[np.sum(np.abs(X))\u003e=20]]\n",
                "\n",
                "# fit model and print out the coefficients\n",
                "# YOUR CODE HERE\n",
                "logit = ...\n",
                "coefs = pd.DataFrame({'variable': X.columns , 'coef': logit.coef_[0]})\n",
                "\n",
                "# define `propensity scores`\n",
                "propensity_scores = logit.predict_proba(X)[:,1]\n",
                "umass['propensity_scores'] = propensity_scores"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(5, 10))\n",
                "plt.barh(y=coefs['variable'],width=coefs['coef'],);\n",
                "plt.xlabel(\"coef value\");"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "ax = sns.boxplot(y=propensity_scores,x=umass['female']);\n",
                "ax.set_title(\"propensity scores\");"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 3.3: Interpret the results\n",
                "\n",
                "* What factors are most related to the probability of being female?\n",
                "* What may be wrong with using this simple logistic regression model with `C=0.03` to estimate propensity scores?  What should be done instead?\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*your answer here*"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 3.4: Estimate the causal effect of `sex`\n",
                "\n",
                "Fit several models to estimate the relationship between `log2pay` and whether or not an employee is `female`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "################\n",
                "# fit several linear regression models to predict `pay_total`:\n",
                "# 1. `female` alone\n",
                "# 2. `female`,`location`,`bargaining_group_title`, and `days_employed`\n",
                "# 3. `female` and `propensity_scores`\n",
                "# 4. `female` alone, but using `propensity_scores` as the 'sample_weight'\n",
                "################\n",
                "\n",
                "# Model1. Baseline model - no control for confounding\n",
                "lm1 = LinearRegression(fit_intercept=True).fit(umass[['female']],umass['log2pay'])\n",
                "print(lm1.coef_[0])\n",
                "\n",
                "X = pd.concat([umass[['female','days_employed']],dummies],\n",
                "              axis=1)\n",
                "\n",
                "# Model 2. Traditional covariate adjustment\n",
                "lm2 = LinearRegression(fit_intercept=True).fit(X,umass['log2pay'])\n",
                "print(lm2.coef_[0])\n",
                "\n",
                "# Model 3. Propensity score as a covariate\n",
                "X = pd.concat([umass[['female']],pd.Series(propensity_scores)],\n",
                "              axis=1)\n",
                "X.columns = X.columns.astype(str) # to avoid error in lm3\n",
                "\n",
                "lm3 = LinearRegression(fit_intercept=True).fit(X,umass['log2pay'])\n",
                "print(lm3.coef_[0])\n",
                "\n",
                "# Model 4. Inverse probability weighting (IPW)\n",
                "#X = pd.concat([umass[['female']],pd.Series(propensity_scores)],\n",
                "#              axis=1)\n",
                "lm4 = LinearRegression(fit_intercept=True).fit(umass[['female']],umass['log2pay'],sample_weight=propensity_scores)\n",
                "print(lm4.coef_[0])\n",
                "\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 3.5: Using propensity scores for matching\n",
                "\n",
                "Create 2 subsets of data:\n",
                "\n",
                "1) `umass_restricted` which removes any females with propensity scores above np.max(propensity_scores[umass['female']==0]) and any males with propensity scores above np.min(propensity_scores[umass['female']==1]).\n",
                "\n",
                "2) `umass_matched` which, for every female, finds the closest matching male based on tehir propensity score.\n",
                "\n",
                "Use these subsets of data to estimate the adjusted difference in `log2pay` and `pay_total` comparing females to males (you can simply fit 2 linear regression models to predict `log2pay` from `female`)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "##############\n",
                "# create the umass_restricted data frame\n",
                "##############\n",
                "\n",
                "max_males = np.max(propensity_scores[umass['female']==0])\n",
                "min_females = np.min(propensity_scores[umass['female']==1])\n",
                "\n",
                "\n",
                "print(max_males, min_females)\n",
                "\n",
                "which_males = (umass['propensity_scores']\u003e=min_females) \u0026 (umass['female']==0)\n",
                "which_females = (umass['propensity_scores']\u003c=max_males) \u0026 (umass['female']==1)\n",
                "print((sum(which_males),sum(which_females)))\n",
                "\n",
                "umass_restricted = umass[which_males | which_females]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "##############\n",
                "# estimate the causal effect\n",
                "##############\n",
                "\n",
                "\n",
                "lm_restricted = LinearRegression(fit_intercept=True).fit(umass_restricted[['female']],\n",
                "                                                         umass_restricted['log2pay'])\n",
                "print(lm_restricted.coef_[0])\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "##############\n",
                "# we create the umass_matched data frame for you\n",
                "##############\n",
                "from psmpy import PsmPy\n",
                "from psmpy.functions import cohenD\n",
                "from psmpy.plotting import *\n",
                "\n",
                "umass['id'] = umass.index\n",
                "X = pd.concat([umass[['days_employed','id','female']],dummies],\n",
                "              axis=1)\n",
                "X = X[X.columns[np.sum(np.abs(X))\u003e=20]]\n",
                "\n",
                "psm = PsmPy(X, treatment='female', indx='id', exclude = [])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "psm.logistic_ps(balance = False)\n",
                "psm.knn_matched(matcher='propensity_score', replacement=True, \n",
                "                caliper=None, drop_unmatched=True)\n",
                "\n",
                "# To get means from matched data:\n",
                "female_pay = umass.loc[psm.df_matched[psm.df_matched['female']==1]['id'].values]['pay_total']\n",
                "male_pay = umass.loc[psm.df_matched[psm.df_matched['female']==0]['id'].values]['pay_total']\n",
                "print(female_pay.mean() - male_pay.mean())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ##############\n",
                "# # we create the umass_matched data frame for you\n",
                "# ##############\n",
                "\n",
                "# from psmpy import PsmPy\n",
                "# from psmpy.functions import cohenD\n",
                "# from psmpy.plotting import *\n",
                "\n",
                "# umass['id']=umass.index\n",
                "# X = pd.concat([umass[['days_employed','id','female']],dummies],\n",
                "#               axis=1)\n",
                "# X = X[X.columns[np.sum(np.abs(X))\u003e=20]]\n",
                "\n",
                "# psm = PsmPy(X, treatment='female', indx='id', exclude = [])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# psm.logistic_ps(balance = False)\n",
                "# psm.knn_matched(matcher='propensity_score', replacement=True, \n",
                "#                 caliper=None, drop_unmatched=True)\n",
                "\n",
                "# psm.df_matched.head()\n",
                "\n",
                "# np.mean(umass.loc[[psm.df_matched['id'][psm.df_matched['female']==1]]])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "##############\n",
                "# Yor code here \n",
                "# use umass_matched data frame to estimate the causal effect\n",
                "##############\n",
                "\n",
                "female_pay = umass['pay_total'].iloc[psm.df_matched['id'][psm.df_matched['female']==1]]\n",
                "male_pay = umass['pay_total'].iloc[psm.df_matched['id'][psm.df_matched['female']==0]]\n",
                "np.mean(female_pay) - np.mean(male_pay)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Question 3.6: Interpret the results\n",
                "\n",
                "What do these results say about whether females get paid less in the UMASS system?  Did the causal approach adjust the estimate much?  Why would this be the case?\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*your answer here*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "fig, axs = plt.subplots(1, 2, figsize=(12, 4), sharey=False)\n",
                "\n",
                "axs[0].hist(umass['pay_total'])\n",
                "axs[0].set_xlabel('pay_total');\n",
                "axs[1].hist(umass['log2pay'])\n",
                "axs[1].set_xlabel('log2pay');\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ]
}
